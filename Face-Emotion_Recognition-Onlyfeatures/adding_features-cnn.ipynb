{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from skimage import io, transform, color\n",
    "from skimage.feature import local_binary_pattern, hog\n",
    "from skimage.filters import gabor_kernel\n",
    "from keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, Concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "# Define function to extract LBP features from an image\n",
    "def extract_lbp_features(image):\n",
    "    # Compute LBP features\n",
    "    lbp_radius = 3\n",
    "    lbp_n_points = 8 * lbp_radius\n",
    "    lbp_method = 'uniform'\n",
    "    lbp_image = local_binary_pattern(image, lbp_n_points, lbp_radius, method=lbp_method)\n",
    "    lbp_histogram, _ = np.histogram(lbp_image, bins=np.arange(0, lbp_n_points + 3), range=(0, lbp_n_points + 2), density=True)\n",
    "    lbp_features = lbp_histogram\n",
    "\n",
    "    return lbp_features\n",
    "\n",
    "# Define function to extract HOG features from an image\n",
    "def extract_hog_features(image):\n",
    "    # Compute HOG features\n",
    "    hog_orientation = 9\n",
    "    hog_pixels_per_cell = (8, 8)\n",
    "    hog_cells_per_block = (3, 3)\n",
    "    hog_block_norm = 'L2-Hys'\n",
    "    hog_features = hog(image, orientations=hog_orientation, pixels_per_cell=hog_pixels_per_cell, cells_per_block=hog_cells_per_block, block_norm=hog_block_norm)\n",
    "\n",
    "    return hog_features\n",
    "\n",
    "# Define function to extract Gabor features from an image\n",
    "def extract_gabor_features(image):\n",
    "    # Compute Gabor features\n",
    "    gabor_frequencies = [0.1, 0.2, 0.3]\n",
    "    gabor_thetas = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "    gabor_features = []\n",
    "    for frequency in gabor_frequencies:\n",
    "        for theta in gabor_thetas:\n",
    "            gabor_kernel_real, gabor_kernel_imag = gabor_kernel(frequency, theta=theta)\n",
    "            gabor_image_real = np.abs(convolve(image, gabor_kernel_real, mode='same'))\n",
    "            gabor_image_imag = np.abs(convolve(image, gabor_kernel_imag, mode='same'))\n",
    "            gabor_image = gabor_image_real + gabor_image_imag\n",
    "            gabor_features.append(np.mean(gabor_image))\n",
    "    gabor_features = np.array(gabor_features)\n",
    "\n",
    "    return gabor_features\n",
    "\n",
    "# Define function to load images and extract features\n",
    "def load_images(folder):\n",
    "    image_filenames = os.listdir(folder)\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in image_filenames:\n",
    "        label = int(filename.split('_')[0])\n",
    "        image = io.imread(os.path.join(folder, filename))\n",
    "        image = transform.resize(image, (48, 48))\n",
    "        gray_image = color.rgb2gray(image)\n",
    "        \n",
    "        # extract features from the image\n",
    "        lbp_features = extract_lbp_features(gray_image)\n",
    "        hog_features = extract_hog_features(gray_image)\n",
    "        gabor_features = extract_gabor_features(gray_image)\n",
    "        \n",
    "        # concatenate the features and original image data\n",
    "        features = np.concatenate((lbp_features, hog_features, gabor_features))\n",
    "        images.append(image)\n",
    "        labels.append(label)\n",
    "        \n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    return images, labels, features\n",
    "\n",
    "# Load training data and extract features\n",
    "train_folder = 'train'\n",
    "train_images, train_labels, train_features = load_images(train_folder)\n",
    "\n",
    "# Load testing data and extract features\n",
    "test_folder = 'test'\n",
    "test_images, test_labels, test_features = load_images(test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data and extract features\n",
    "train_folder = 'train'\n",
    "train_images, train_labels, train_features = load_images(train_folder)\n",
    "\n",
    "# Load testing data and extract features\n",
    "test_folder = 'test'\n",
    "test_images, test_labels, test_features = load_images(test_folder)\n",
    "\n",
    "# Define the neural network architecture\n",
    "input_layer = Input(shape=(48, 48, 3))\n",
    "x = Conv2D(32, kernel_size=(3,3), activation='relu')(input_layer)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(64, kernel_size=(3,3), activation='relu')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Conv2D(128, kernel_size=(3,3), activation='relu')(x)\n",
    "x = MaxPooling2D()(x)\n",
    "x = Flatten()(x)\n",
    "\n",
    "lbp_input_layer = Input(shape=(26,))\n",
    "hog_input_layer = Input(shape=(3780,))\n",
    "gabor_input_layer = Input(shape=(32,))\n",
    "\n",
    "concat_layer = concatenate([x, lbp_input_layer, hog_input_layer, gabor_input_layer])\n",
    "hidden_layer = Dense(512, activation='relu')(concat_layer)\n",
    "output_layer = Dense(7, activation='softmax')(hidden_layer)\n",
    "\n",
    "model = Model(inputs=[input_layer, lbp_input_layer, hog_input_layer, gabor_input_layer], outputs=output_layer)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
