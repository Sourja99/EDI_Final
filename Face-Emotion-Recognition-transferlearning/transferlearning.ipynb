{"cells":[{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["c:\\Users\\HP\\Desktop\\face_emotion_github\\Face-Emotion-Recognition-transferlearning\n"]}],"source":["import os\n","\n","# os.chdir(r\"C:\\Users\\HP\\Desktop\\face_emotion_github\\Face-Emotion-Recognition-main\")\n","print(os.getcwd())"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":1776,"status":"ok","timestamp":1611834176378,"user":{"displayName":"ENG18CS0105 Gayathri Devi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiX2uOvt8QZIQp6xcdbO0E_F8VGVrg797uz1dVWKng=s64","userId":"09832506685730138303"},"user_tz":-330},"id":"SoRnCx39qVmW"},"outputs":[],"source":["#Import ML required packages\n","from tensorflow.keras.applications import VGG16\n","from tensorflow.keras.models import Model\n","import numpy as np\n","import pandas as pd \n","import keras\n","from keras.utils import to_categorical\n","#Import Libraries before model creation\n","from keras.models import Sequential\n","from keras.layers import Conv2D,MaxPooling2D,BatchNormalization\n","from keras.layers import Dense,Dropout,Activation,Flatten\n","from keras.losses import categorical_crossentropy\n","from keras.optimizers import Adam\n","from keras.regularizers import l2\n","from keras.callbacks import EarlyStopping\n","from sklearn.metrics import accuracy_score\n","from keras.preprocessing.image import ImageDataGenerator\n","from sklearn.metrics import confusion_matrix,classification_report\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","%matplotlib inline"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"]}],"source":["import tensorflow as tf\n","print(tf.config.list_physical_devices())"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" /device:CPU:0 || Unnamed device || CPU || 256.0 MiB\n"," /device:GPU:0 ||  NVIDIA GeForce RTX 3050 Laptop GPU || GPU || 1.6 GiB\n"]}],"source":["from tensorflow.python.client import device_lib\n","devices = device_lib.list_local_devices()\n","\n","def sizeof_fmt(num, suffix='B'):\n","    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n","        if abs(num) < 1024.0:\n","            return \"%3.1f %s%s\" % (num, unit, suffix)\n","        num /= 1024.0\n","    return \"%.1f%s%s\" % (num, 'Yi', suffix)\n","\n","for d in devices:\n","    t = d.device_type\n","    name = d.physical_device_desc\n","    l = [item.split(':',1) for item in name.split(\", \")]\n","    name_attr = dict([x for x in l if len(x)==2])\n","    dev = name_attr.get('name', 'Unnamed device')\n","    print(f\" {d.name} || {dev} || {t} || {sizeof_fmt(d.memory_limit)}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["#### LOAD DATASET"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 28709 images belonging to 7 classes.\n","Found 7178 images belonging to 7 classes.\n"]}],"source":["# Define data augmentation parameters\n","datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=20,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    horizontal_flip=True\n",")\n","\n","# Load and preprocess the training and validation data\n","train_generator = datagen.flow_from_directory(\n","    '../Data/Fer2013/archive/train/',\n","    target_size=(48, 48),\n","    color_mode='rgb',\n","    batch_size=32,\n","    class_mode='categorical',\n","    classes=['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise'],\n","    shuffle=True\n",")\n","\n","val_generator = datagen.flow_from_directory(\n","    '../Data/Fer2013/archive/test/',\n","    target_size=(48, 48),\n","    color_mode='rgb',\n","    batch_size=32,\n","    class_mode='categorical',\n","    classes=['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise'],\n","    shuffle=True\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Original VGG-16 & Transfer Learning"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[],"source":["# Load the VGG16 model without the top layer\n","base_model = VGG16(include_top=False, input_shape=(48, 48, 3))"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":["# Freeze the pre-trained layers in the base model\n","for layer in base_model.layers:\n","    layer.trainable = False\n"]},{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_4 (InputLayer)        [(None, 48, 48, 3)]       0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 48, 48, 64)        1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 48, 48, 64)        36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 24, 24, 64)        0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 24, 24, 128)       73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 24, 24, 128)       147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 12, 12, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 12, 12, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 12, 12, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 12, 12, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 6, 6, 256)         0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 6, 6, 512)         1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 3, 3, 512)         2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 3, 3, 512)         2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 3, 3, 512)         2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n","                                                                 \n"," flatten_4 (Flatten)         (None, 512)               0         \n","                                                                 \n"," dense_12 (Dense)            (None, 1024)              525312    \n","                                                                 \n"," dropout_8 (Dropout)         (None, 1024)              0         \n","                                                                 \n"," dense_13 (Dense)            (None, 512)               524800    \n","                                                                 \n"," dropout_9 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_14 (Dense)            (None, 7)                 3591      \n","                                                                 \n","=================================================================\n","Total params: 15,768,391\n","Trainable params: 1,053,703\n","Non-trainable params: 14,714,688\n","_________________________________________________________________\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\HP\\miniconda3\\envs\\tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  super().__init__(name, **kwargs)\n"]}],"source":["# Add custom classification layers on top of the pre-trained model\n","x = base_model.output\n","x = Flatten()(x)\n","x = Dense(1024, activation='relu')(x)\n","x = Dropout(0.5)(x)\n","x = Dense(512, activation='relu')(x)\n","x = Dropout(0.5)(x)\n","predictions = Dense(7, activation='softmax')(x)\n","\n","# Create the transfer learning model\n","model = Model(inputs=base_model.input, outputs=predictions)\n","\n","# Compile the model\n","model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n","model.summary()"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/50\n","898/898 [==============================] - 76s 78ms/step - loss: 1.7510 - accuracy: 0.2880 - val_loss: 1.6924 - val_accuracy: 0.3260\n","Epoch 2/50\n","898/898 [==============================] - 51s 57ms/step - loss: 1.7036 - accuracy: 0.3207 - val_loss: 1.6593 - val_accuracy: 0.3501\n","Epoch 3/50\n","898/898 [==============================] - 48s 53ms/step - loss: 1.6876 - accuracy: 0.3251 - val_loss: 1.6500 - val_accuracy: 0.3458\n","Epoch 4/50\n","898/898 [==============================] - 49s 54ms/step - loss: 1.6756 - accuracy: 0.3353 - val_loss: 1.6479 - val_accuracy: 0.3502\n","Epoch 5/50\n","898/898 [==============================] - 51s 57ms/step - loss: 1.6728 - accuracy: 0.3354 - val_loss: 1.6321 - val_accuracy: 0.3558\n","Epoch 6/50\n","898/898 [==============================] - 50s 55ms/step - loss: 1.6693 - accuracy: 0.3366 - val_loss: 1.6399 - val_accuracy: 0.3508\n","Epoch 7/50\n","898/898 [==============================] - 49s 55ms/step - loss: 1.6611 - accuracy: 0.3433 - val_loss: 1.6362 - val_accuracy: 0.3610\n","Epoch 8/50\n","898/898 [==============================] - 48s 53ms/step - loss: 1.6602 - accuracy: 0.3434 - val_loss: 1.6351 - val_accuracy: 0.3660\n","Epoch 9/50\n","898/898 [==============================] - 48s 53ms/step - loss: 1.6586 - accuracy: 0.3396 - val_loss: 1.6292 - val_accuracy: 0.3653\n","Epoch 10/50\n","898/898 [==============================] - 52s 58ms/step - loss: 1.6524 - accuracy: 0.3464 - val_loss: 1.6337 - val_accuracy: 0.3550\n","Epoch 11/50\n","898/898 [==============================] - 49s 54ms/step - loss: 1.6492 - accuracy: 0.3486 - val_loss: 1.6259 - val_accuracy: 0.3598\n","Epoch 12/50\n","898/898 [==============================] - 49s 54ms/step - loss: 1.6458 - accuracy: 0.3480 - val_loss: 1.6368 - val_accuracy: 0.3508\n","Epoch 13/50\n","898/898 [==============================] - 46s 51ms/step - loss: 1.6453 - accuracy: 0.3469 - val_loss: 1.6185 - val_accuracy: 0.3675\n","Epoch 14/50\n","898/898 [==============================] - 49s 54ms/step - loss: 1.6439 - accuracy: 0.3500 - val_loss: 1.6271 - val_accuracy: 0.3677\n","Epoch 15/50\n","898/898 [==============================] - 55s 61ms/step - loss: 1.6388 - accuracy: 0.3541 - val_loss: 1.6140 - val_accuracy: 0.3661\n","Epoch 16/50\n","898/898 [==============================] - 58s 65ms/step - loss: 1.6386 - accuracy: 0.3504 - val_loss: 1.6305 - val_accuracy: 0.3660\n","Epoch 17/50\n","898/898 [==============================] - 46s 52ms/step - loss: 1.6363 - accuracy: 0.3525 - val_loss: 1.6139 - val_accuracy: 0.3586\n","Epoch 18/50\n","898/898 [==============================] - 46s 52ms/step - loss: 1.6353 - accuracy: 0.3579 - val_loss: 1.6197 - val_accuracy: 0.3679\n","Epoch 19/50\n","898/898 [==============================] - 49s 54ms/step - loss: 1.6346 - accuracy: 0.3566 - val_loss: 1.6222 - val_accuracy: 0.3559\n","Epoch 20/50\n","898/898 [==============================] - 50s 56ms/step - loss: 1.6308 - accuracy: 0.3551 - val_loss: 1.6052 - val_accuracy: 0.3713\n","Epoch 21/50\n","898/898 [==============================] - 50s 55ms/step - loss: 1.6354 - accuracy: 0.3556 - val_loss: 1.6116 - val_accuracy: 0.3753\n","Epoch 22/50\n","898/898 [==============================] - 49s 54ms/step - loss: 1.6271 - accuracy: 0.3596 - val_loss: 1.6043 - val_accuracy: 0.3738\n","Epoch 23/50\n","898/898 [==============================] - 47s 53ms/step - loss: 1.6299 - accuracy: 0.3547 - val_loss: 1.6090 - val_accuracy: 0.3771\n","Epoch 24/50\n","898/898 [==============================] - 50s 56ms/step - loss: 1.6268 - accuracy: 0.3609 - val_loss: 1.6157 - val_accuracy: 0.3722\n","Epoch 25/50\n","898/898 [==============================] - 51s 57ms/step - loss: 1.6254 - accuracy: 0.3627 - val_loss: 1.6109 - val_accuracy: 0.3672\n","Epoch 26/50\n","898/898 [==============================] - 49s 55ms/step - loss: 1.6221 - accuracy: 0.3581 - val_loss: 1.6049 - val_accuracy: 0.3653\n","Epoch 27/50\n","898/898 [==============================] - 48s 53ms/step - loss: 1.6243 - accuracy: 0.3594 - val_loss: 1.6063 - val_accuracy: 0.3728\n","Epoch 28/50\n","898/898 [==============================] - 47s 52ms/step - loss: 1.6240 - accuracy: 0.3615 - val_loss: 1.6099 - val_accuracy: 0.3718\n","Epoch 29/50\n","898/898 [==============================] - 50s 55ms/step - loss: 1.6207 - accuracy: 0.3645 - val_loss: 1.5943 - val_accuracy: 0.3784\n","Epoch 30/50\n","898/898 [==============================] - 51s 56ms/step - loss: 1.6258 - accuracy: 0.3594 - val_loss: 1.6140 - val_accuracy: 0.3678\n","Epoch 31/50\n","898/898 [==============================] - 48s 54ms/step - loss: 1.6197 - accuracy: 0.3611 - val_loss: 1.6093 - val_accuracy: 0.3702\n","Epoch 32/50\n","898/898 [==============================] - 47s 53ms/step - loss: 1.6209 - accuracy: 0.3598 - val_loss: 1.6102 - val_accuracy: 0.3682\n","Epoch 33/50\n","898/898 [==============================] - 48s 53ms/step - loss: 1.6217 - accuracy: 0.3635 - val_loss: 1.6064 - val_accuracy: 0.3711\n","Epoch 34/50\n","898/898 [==============================] - 49s 54ms/step - loss: 1.6239 - accuracy: 0.3622 - val_loss: 1.6146 - val_accuracy: 0.3642\n","Epoch 35/50\n","898/898 [==============================] - 40s 45ms/step - loss: 1.6217 - accuracy: 0.3632 - val_loss: 1.5977 - val_accuracy: 0.3717\n","Epoch 36/50\n","898/898 [==============================] - 24s 26ms/step - loss: 1.6197 - accuracy: 0.3622 - val_loss: 1.6102 - val_accuracy: 0.3677\n","Epoch 37/50\n","898/898 [==============================] - 24s 27ms/step - loss: 1.6231 - accuracy: 0.3630 - val_loss: 1.5982 - val_accuracy: 0.3746\n","Epoch 38/50\n","898/898 [==============================] - 24s 27ms/step - loss: 1.6185 - accuracy: 0.3660 - val_loss: 1.5980 - val_accuracy: 0.3766\n","Epoch 39/50\n","898/898 [==============================] - 24s 27ms/step - loss: 1.6132 - accuracy: 0.3679 - val_loss: 1.6162 - val_accuracy: 0.3678\n","Epoch 40/50\n","898/898 [==============================] - 24s 27ms/step - loss: 1.6167 - accuracy: 0.3654 - val_loss: 1.6039 - val_accuracy: 0.3675\n","Epoch 41/50\n","898/898 [==============================] - 25s 27ms/step - loss: 1.6171 - accuracy: 0.3685 - val_loss: 1.6003 - val_accuracy: 0.3696\n","Epoch 42/50\n","898/898 [==============================] - 25s 27ms/step - loss: 1.6192 - accuracy: 0.3630 - val_loss: 1.6101 - val_accuracy: 0.3646\n","Epoch 43/50\n","898/898 [==============================] - 25s 27ms/step - loss: 1.6168 - accuracy: 0.3651 - val_loss: 1.5970 - val_accuracy: 0.3675\n","Epoch 44/50\n","898/898 [==============================] - 25s 28ms/step - loss: 1.6079 - accuracy: 0.3693 - val_loss: 1.6114 - val_accuracy: 0.3607\n","Epoch 45/50\n","898/898 [==============================] - 26s 29ms/step - loss: 1.6127 - accuracy: 0.3663 - val_loss: 1.6074 - val_accuracy: 0.3697\n","Epoch 46/50\n","898/898 [==============================] - 25s 28ms/step - loss: 1.6140 - accuracy: 0.3687 - val_loss: 1.6125 - val_accuracy: 0.3605\n","Epoch 47/50\n","898/898 [==============================] - 26s 28ms/step - loss: 1.6087 - accuracy: 0.3716 - val_loss: 1.6061 - val_accuracy: 0.3720\n","Epoch 48/50\n","898/898 [==============================] - 25s 28ms/step - loss: 1.6126 - accuracy: 0.3686 - val_loss: 1.6010 - val_accuracy: 0.3766\n","Epoch 49/50\n","898/898 [==============================] - 26s 29ms/step - loss: 1.6169 - accuracy: 0.3632 - val_loss: 1.6045 - val_accuracy: 0.3756\n","Epoch 50/50\n","898/898 [==============================] - 27s 30ms/step - loss: 1.6113 - accuracy: 0.3701 - val_loss: 1.6079 - val_accuracy: 0.3756\n"]},{"data":{"text/plain":["<keras.callbacks.History at 0x1a08e4e7be0>"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["# Train the model\n","# model.fit(train_generator, epochs=50, validation_data=val_generator)\n","model.fit(train_generator, epochs=50, validation_data=val_generator)"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_7448\\1447940332.py:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n","  eval = model.evaluate_generator(val_generator)\n"]},{"name":"stdout","output_type":"stream","text":["[1.6024103164672852, 0.38548341393470764]\n"]}],"source":["eval = model.evaluate_generator(val_generator)\n","print(eval)"]},{"cell_type":"code","execution_count":57,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_7448\\557385363.py:1: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n","  eval_metrics = model.evaluate_generator(val_generator)\n"]},{"name":"stdout","output_type":"stream","text":["Test accuracy: 0.38186123967170715\n"]}],"source":["eval_metrics = model.evaluate_generator(val_generator)\n","test_acc = eval_metrics[1]\n","print(\"Test accuracy:\", test_acc)"]},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1224,"status":"ok","timestamp":1611835013474,"user":{"displayName":"ENG18CS0105 Gayathri Devi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiX2uOvt8QZIQp6xcdbO0E_F8VGVrg797uz1dVWKng=s64","userId":"09832506685730138303"},"user_tz":-330},"id":"LL09_pI_eWoH","outputId":"72afaac5-a211-40df-d0db-1e06abc7d94b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Saved model to disk\n"]}],"source":["import json\n","model_json = model.to_json()\n","with open(\"../Models/transferlearning/onlytransfer/model.json\", \"w\") as json_file:\n","  json_file.write(model_json)\n","  model.save_weights(\"../Models/transferlearning/onlytransfer/model.h5\")\n","print(\"Saved model to disk\")"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMIRuK51DJ/JhWcOkFYt6HX","collapsed_sections":[],"mount_file_id":"1LJo0uodnUTrGjZGlle_-lin_Mdk3jH2d","name":"Face-emotion-recognition.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}
