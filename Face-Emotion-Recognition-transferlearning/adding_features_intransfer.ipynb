{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n this example, we loaded the pre-trained VGG16 model without the classification layers and froze the layers in the pre-trained model. Then we added a few fully connected layers on top of the pre-trained model for classification. We trained the model with data augmentation and evaluated it on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load the pre-trained VGG16 model without the classification layers\n",
    "vgg = VGG16(include_top=False, input_shape=(width, height, 3))\n",
    "\n",
    "# Freeze the layers in the pre-trained model\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add the classification layers on top of the pre-trained model\n",
    "x = Flatten()(vgg.output)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the new model\n",
    "model = Model(inputs=vgg.input, outputs=x)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999), metrics=['accuracy'])\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model with data augmentation\n",
    "history = model.fit(datagen.flow(train_X, train_Y, batch_size=batch_size),\n",
    "                    epochs=50, \n",
    "                    validation_data=(val_X, val_Y),\n",
    "                    steps_per_epoch=len(train_X) // batch_size,\n",
    "                    callbacks=[es])\n",
    "                    \n",
    "# Evaluate the model on the testing set\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', test_loss)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
