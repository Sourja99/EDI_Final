{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the landmark_input and texture_input are additional inputs that represent facial landmark points and texture descriptors, respectively. The Concatenate() layer is used to concatenate these additional features with the output of the convolutional layers before the dense layers. The complete model is then compiled and trained using all inputs (X_train, landmark_train, and texture_train) with their corresponding labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "\n",
    "# Load the face detector and landmark predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('path/to/shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "# Function to extract LBP features from an image\n",
    "def extract_lbp_features(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    lbp = cv2.spatial_histogram(gray, [8,8], 256, True)\n",
    "    return lbp.flatten()\n",
    "\n",
    "# Function to extract facial landmarks and LBP features from an image\n",
    "def extract_features(image_path):\n",
    "    image = cv2.imread(image_path)\n",
    "    # Detect faces in the image\n",
    "    faces = detector(image)\n",
    "    # Extract landmark and LBP features for each face\n",
    "    landmarks = []\n",
    "    textures = []\n",
    "    for face in faces:\n",
    "        # Extract landmark features\n",
    "        shape = predictor(image, face)\n",
    "        landmarks.append(np.array([(shape.part(i).x, shape.part(i).y) for i in range(68)]))\n",
    "        # Extract texture features\n",
    "        texture = extract_lbp_features(cv2.resize(image[face.top():face.bottom(), face.left():face.right()], (256, 256)))\n",
    "        textures.append(texture)\n",
    "    return np.array(landmarks), np.array(textures)\n",
    "\n",
    "# Example usage\n",
    "landmark_train = []\n",
    "texture_train = []\n",
    "landmark_val = []\n",
    "texture_val = []\n",
    "\n",
    "# Iterate over training images\n",
    "for i in range(len(train_image_paths)):\n",
    "    landmarks, textures = extract_features(train_image_paths[i])\n",
    "    landmark_train.append(landmarks)\n",
    "    texture_train.append(textures)\n",
    "\n",
    "# Iterate over validation images\n",
    "for i in range(len(val_image_paths)):\n",
    "    landmarks, textures = extract_features(val_image_paths[i])\n",
    "    landmark_val.append(landmarks)\n",
    "    texture_val.append(textures)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "landmark_train = np.array(landmark_train)\n",
    "texture_train = np.array(texture_train)\n",
    "landmark_val = np.array(landmark_val)\n",
    "texture_val = np.array(texture_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have your landmark and texture features stored in arrays\n",
    "landmark = ...\n",
    "texture = ...\n",
    "\n",
    "# Split the landmark and texture features into training and validation sets\n",
    "landmark_train, landmark_val, texture_train, texture_val = train_test_split(landmark, texture, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layers\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Add feature extraction layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# Define additional feature inputs\n",
    "landmark_input = Input(shape=(68, 2), name='landmark_input')\n",
    "texture_input = Input(shape=(256,), name='texture_input')\n",
    "\n",
    "# Concatenate features with output of convolutional layers\n",
    "conv_output = model.layers[-2].output\n",
    "concat_layer = Concatenate()([conv_output, landmark_input, texture_input])\n",
    "\n",
    "# Add dense layers\n",
    "dense_layer = Dense(256, activation='relu')(concat_layer)\n",
    "output_layer = Dense(num_classes, activation='softmax')(dense_layer)\n",
    "\n",
    "# Define the complete model\n",
    "complete_model = Model(inputs=[model.input, landmark_input, texture_input], outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "complete_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])\n",
    "\n",
    "# Train the model with all inputs\n",
    "history = complete_model.fit([X_train, landmark_train, texture_train], y_train, epochs=10, batch_size=32, validation_data=([X_val, landmark_val, texture_val], y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Trying adding features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from skimage.feature import hog, local_binary_pattern\n",
    "from skimage.filters import gabor_kernel\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# load the landmark_train, texture_train, landmark_val, and texture_val datasets\n",
    "\n",
    "# extract HOG features\n",
    "def extract_hog_features(images):\n",
    "    features = []\n",
    "    for img in images:\n",
    "        img = cv2.resize(img, (64, 64))\n",
    "        fd = hog(img, orientations=9, pixels_per_cell=(8, 8),\n",
    "                 cells_per_block=(2, 2), visualize=False, multichannel=True)\n",
    "        features.append(fd)\n",
    "    return features\n",
    "\n",
    "train_hog = extract_hog_features(landmark_train)\n",
    "val_hog = extract_hog_features(landmark_val)\n",
    "\n",
    "# extract LBP features\n",
    "def extract_lbp_features(images):\n",
    "    features = []\n",
    "    for img in images:\n",
    "        img = cv2.resize(img, (64, 64))\n",
    "        lbp = local_binary_pattern(img, 8, 1, method='uniform')\n",
    "        hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 10), range=(0, 9))\n",
    "        hist = hist.astype(\"float\")\n",
    "        hist /= (hist.sum() + 1e-7)\n",
    "        features.append(hist)\n",
    "    return features\n",
    "\n",
    "train_lbp = extract_lbp_features(texture_train)\n",
    "val_lbp = extract_lbp_features(texture_val)\n",
    "\n",
    "# extract Gabor features\n",
    "def extract_gabor_features(images):\n",
    "    features = []\n",
    "    for img in images:\n",
    "        img = cv2.resize(img, (64, 64))\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        feats = []\n",
    "        for k in range(3):\n",
    "            kernel = np.real(gabor_kernel(0.4, theta=k*np.pi/3, sigma_x=1, sigma_y=1))\n",
    "            filtered = cv2.filter2D(gray_img, cv2.CV_8UC3, kernel)\n",
    "            feats.append(filtered)\n",
    "        feats = np.array(feats)\n",
    "        features.append(feats.flatten())\n",
    "    return features\n",
    "\n",
    "train_gabor = extract_gabor_features(texture_train)\n",
    "val_gabor = extract_gabor_features(texture_val)\n",
    "\n",
    "# concatenate all features\n",
    "train_features = np.concatenate([train_hog, train_lbp, train_gabor], axis=1)\n",
    "val_features = np.concatenate([val_hog, val_lbp, val_gabor], axis=1)\n",
    "\n",
    "# define the model architecture\n",
    "inputs = Input(shape=(train_features.shape[1],))\n",
    "x = Dense(128, activation='relu')(inputs)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "outputs = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999), metrics=['accuracy'])\n",
    "\n",
    "# train the model\n",
    "history = model.fit(train_features, train_Y, batch_size=32, epochs=50, validation_data=(val_features, val_Y))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
